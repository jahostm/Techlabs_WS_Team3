{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dongv\\AppData\\Local\\Temp\\ipykernel_24832\\3635927244.py:3: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_stocks = pd.read_csv('clean_225_stocks_data.csv', parse_dates=['Date'])\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "df_earthquake = pd.read_csv('clean_major_earthquakes.csv', parse_dates=['date']) # parse_dates convert the 'date' column from a string(text) format into a datatime format\n",
    "df_stocks = pd.read_csv('unclean_225_stocks_data.csv', parse_dates=['Date'])\n",
    "df_companies = pd.read_csv('N225_companies.csv', sep=';') # the file uses semicolons (;) as a delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date                Open              Close  Volume  Ticker\n",
      "0  2000-01-04   96.17342799484351  95.56473541259766  296000  1332.T\n",
      "1  2000-01-05   99.82558348831859  95.56473541259766  637000  1332.T\n",
      "2  2000-01-06  101.65168214575645  99.21691131591797  411000  1332.T\n",
      "3  2000-01-07   98.60819357245632  102.8690414428711  645000  1332.T\n",
      "4  2000-01-10   102.8690414428711  102.8690414428711       0  1332.T\n"
     ]
    }
   ],
   "source": [
    "# Display dataset\n",
    "print(df_stocks.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with invalid dates:\n",
      "Empty DataFrame\n",
      "Columns: [Date, Open, Close, Volume, Ticker]\n",
      "Index: []\n",
      "\n",
      "Missing values in each column:\n",
      "Date      0\n",
      "Open      0\n",
      "Close     0\n",
      "Volume    0\n",
      "Ticker    0\n",
      "dtype: int64\n",
      "\n",
      "Missing dates:\n",
      "DatetimeIndex(['1999-05-08', '1999-05-09', '1999-05-15', '1999-05-16',\n",
      "               '1999-05-22', '1999-05-23', '1999-05-29', '1999-05-30',\n",
      "               '1999-06-05', '1999-06-06',\n",
      "               ...\n",
      "               '2025-01-19', '2025-01-25', '2025-01-26', '2025-02-01',\n",
      "               '2025-02-02', '2025-02-08', '2025-02-09', '2025-02-11',\n",
      "               '2025-02-15', '2025-02-16'],\n",
      "              dtype='datetime64[ns]', length=2970, freq=None)\n",
      "\n",
      "Duplicate rows:\n",
      "Empty DataFrame\n",
      "Columns: [Date, Open, Close, Volume, Ticker]\n",
      "Index: []\n",
      "\n",
      "Rows with Volume = 0:\n",
      "              Date         Open        Close Volume  Ticker\n",
      "1310834 2016-07-11  2552.135498  2552.135498      0  9984.T\n",
      "1311084 2017-07-17  4330.719238  4330.719238      0  9984.T\n",
      "1311103 2017-08-11  4162.359375  4162.359375      0  9984.T\n",
      "1311129 2017-09-18  4083.888428  4083.888428      0  9984.T\n",
      "1311144 2017-10-09  4373.230469  4373.230469      0  9984.T\n",
      "1311163 2017-11-03  4867.620605  4867.620605      0  9984.T\n",
      "1311177 2017-11-23  4600.164062  4600.164062      0  9984.T\n",
      "1311204 2018-01-01   4252.61377   4252.61377      0  9984.T\n",
      "1311205 2018-01-02   4252.61377   4252.61377      0  9984.T\n",
      "1311206 2018-01-03   4252.61377   4252.61377      0  9984.T\n",
      "1311209 2018-01-08  4405.649902  4405.649902      0  9984.T\n",
      "1311234 2018-02-12  4199.217285  4199.217285      0  9984.T\n",
      "1311261 2018-03-21  4078.121826  4078.121826      0  9984.T\n",
      "1311289 2018-04-30  4063.687012  4063.687012      0  9984.T\n",
      "1311292 2018-05-03  4058.428711  4058.428711      0  9984.T\n",
      "1311293 2018-05-04  4058.428711  4058.428711      0  9984.T\n",
      "1311344 2018-07-16  4647.354492  4647.354492      0  9984.T\n",
      "1311389 2018-09-17  5231.979004  5231.979004      0  9984.T\n",
      "1311394 2018-09-24  5279.781738  5279.781738      0  9984.T\n",
      "1311404 2018-10-08  5304.804688  5304.804688      0  9984.T\n",
      "1311438 2018-11-23  4208.877441  4208.877441      0  9984.T\n",
      "1311459 2018-12-24  3650.376465  3650.376465      0  9984.T\n",
      "1311464 2018-12-31  3499.015869  3499.015869      0  9984.T\n"
     ]
    }
   ],
   "source": [
    "# Check for missing, duplucate data\n",
    "\n",
    "# 1. Remove rows where the 'Date' column doesn't match the expected date format\n",
    "df_stocks = df_stocks[df_stocks['Date'].str.match(r'\\d{4}-\\d{2}-\\d{2}', na=False)]\n",
    "\n",
    "# 2. Convert the 'Date' column to datetime\n",
    "df_stocks['Date'] = pd.to_datetime(df_stocks['Date'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# 3. Check for rows with invalid dates\n",
    "invalid_dates = df_stocks[df_stocks['Date'].isna()]\n",
    "print(\"Rows with invalid dates:\")\n",
    "print(invalid_dates)\n",
    "\n",
    "# 4. Drop rows with invalid dates (optional)\n",
    "df_stocks = df_stocks.dropna(subset=['Date'])\n",
    "\n",
    "# 5. Check for missing values in each column\n",
    "missing_values = df_stocks.isnull().sum()\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# 6. Check for missing rows (e.g., gaps in the Date column)\n",
    "full_date_range = pd.date_range(start=df_stocks['Date'].min(), end=df_stocks['Date'].max(), freq='D')\n",
    "missing_dates = full_date_range.difference(df_stocks['Date'])\n",
    "print(\"\\nMissing dates:\")\n",
    "print(missing_dates)\n",
    "\n",
    "# 7. Check for duplicate rows\n",
    "duplicate_rows = df_stocks[df_stocks.duplicated()]\n",
    "print(\"\\nDuplicate rows:\")\n",
    "print(duplicate_rows)\n",
    "\n",
    "# 8. Check for invalid values (e.g., Volume = 0)\n",
    "invalid_volume = df_stocks[df_stocks['Volume'] == 0]\n",
    "print(\"\\nRows with Volume = 0:\")\n",
    "print(invalid_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Ticker  Company_name Industry       Date                Open  \\\n",
      "1824  1332.T  NISSUI CORP.  Fishery 2007-01-04  496.98624286410853   \n",
      "1825  1332.T  NISSUI CORP.  Fishery 2007-01-05    510.323593674323   \n",
      "1826  1332.T  NISSUI CORP.  Fishery 2007-01-09   513.8332764679333   \n",
      "1827  1332.T  NISSUI CORP.  Fishery 2007-01-10  505.40978064903845   \n",
      "1828  1332.T  NISSUI CORP.  Fishery 2007-01-11   497.6882201100624   \n",
      "\n",
      "                   Close   Volume  \n",
      "1824  500.49603271484375   855800  \n",
      "1825   520.8529663085938  4653800  \n",
      "1826    510.323486328125  2779700  \n",
      "1827   492.7745361328125  3638400  \n",
      "1828  490.66864013671875  2608400  \n"
     ]
    }
   ],
   "source": [
    "# Merge df_stocks with df_companies on 'Ticker'\n",
    "merged_df = pd.merge(\n",
    "    df_stocks, \n",
    "    df_companies, \n",
    "    on='Ticker', \n",
    "    how='left'  # Use 'left' to keep all rows from df_stocks\n",
    ")\n",
    "\n",
    "# Reorder the columns\n",
    "column_order = ['Number', 'Ticker', 'Company_name', 'Industry', 'Date', 'Open', 'Close', 'Volume']\n",
    "merged_df = merged_df[column_order]\n",
    "\n",
    "# Drop the 'Number' column\n",
    "merged_df = merged_df.drop(columns=['Number'])\n",
    "\n",
    "# Filter data to include only rows from the year 2007 onward\n",
    "merged_df = merged_df[merged_df['Date'] >= '2007-01-01']\n",
    "\n",
    " # Convert 'Date' column to datetime format\n",
    "merged_df['Date'] = pd.to_datetime(merged_df['Date'])\n",
    "    \n",
    "# Display the resulting DataFrame\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result to new csv file\n",
    "#merged_df.to_csv(\"clean_225_stocks_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
