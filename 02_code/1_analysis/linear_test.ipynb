{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data for ticker ^NYA to data/test/linear/^NYA.csv\n",
      "Saved data for ticker ^IXIC to data/test/linear/^IXIC.csv\n",
      "Saved data for ticker ^FTSE to data/test/linear/^FTSE.csv\n",
      "Saved data for ticker ^NSEI to data/test/linear/^NSEI.csv\n",
      "Saved data for ticker ^BSESN to data/test/linear/^BSESN.csv\n",
      "Saved data for ticker ^N225 to data/test/linear/^N225.csv\n",
      "Saved data for ticker 000001.SS to data/test/linear/000001.SS.csv\n",
      "Saved data for ticker ^N100 to data/test/linear/^N100.csv\n",
      "Saved data for ticker ^DJI to data/test/linear/^DJI.csv\n",
      "Saved data for ticker ^GSPC to data/test/linear/^GSPC.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = 'data/test/linear/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each ticker in the markets.csv file\n",
    "for _, market_row in df_markets.iterrows():\n",
    "    ticker = market_row['Ticker']\n",
    "    \n",
    "    # Convert latitude and longitude to float\n",
    "    try:\n",
    "        latitude = float(market_row['Latitude'])\n",
    "        longitude = float(market_row['Longitude'])\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Invalid latitude or longitude for ticker {ticker}. Ensure they are numeric values.\") from e\n",
    "\n",
    "    # Validate latitude and longitude ranges\n",
    "    if not (-90.0 <= latitude <= 90.0):\n",
    "        raise ValueError(f\"Latitude {latitude} for ticker {ticker} is out of bounds. Must be between -90.0 and 90.0.\")\n",
    "    if not (-180.0 <= longitude <= 180.0):\n",
    "        raise ValueError(f\"Longitude {longitude} for ticker {ticker} is out of bounds. Must be between -180.0 and 180.0.\")\n",
    "\n",
    "    # Convert close time to datetime.time object\n",
    "    try:\n",
    "        close_time = pd.to_datetime(market_row['close'], format='%H:%M', errors='coerce').time()\n",
    "        if pd.isna(close_time):\n",
    "            raise ValueError(f\"Invalid or missing close time for ticker {ticker}. Ensure it is in 'HH:MM' format.\")\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Invalid close time format for ticker {ticker}. Ensure it is in 'HH:MM' format.\") from e\n",
    "\n",
    "    # Find the time zone based on latitude and longitude\n",
    "    timezone_str = tf.timezone_at(lat=latitude, lng=longitude)\n",
    "    if timezone_str is None:\n",
    "        raise ValueError(f\"Could not determine time zone for ticker {ticker} at coordinates ({latitude}, {longitude})\")\n",
    "    tz = timezone(timezone_str)\n",
    "\n",
    "    # Read the stock market data for the current ticker\n",
    "    df_ticker = pd.read_csv(f'data/test/{ticker}.csv')\n",
    "    df_ticker.rename(columns={'Date': 'date'}, inplace=True)  # Rename 'Date' column to 'date'\n",
    "\n",
    "    # Convert df_ticker date column to the respective time zone\n",
    "    df_ticker['date'] = pd.to_datetime(df_ticker['date']).dt.tz_localize(tz)\n",
    "\n",
    "    # Normalize the earthquake data to the close time of the current ticker\n",
    "    if df_eq['date'].dt.tz is None:\n",
    "        # If the column is timezone-naive, localize it to UTC first\n",
    "        df_eq['date_close'] = df_eq['date'].dt.tz_localize('UTC').dt.tz_convert(tz).dt.normalize() + pd.Timedelta(hours=close_time.hour, minutes=close_time.minute)\n",
    "    else:\n",
    "        # If the column is already timezone-aware, convert it directly\n",
    "        df_eq['date_close'] = df_eq['date'].dt.tz_convert(tz).dt.normalize() + pd.Timedelta(hours=close_time.hour, minutes=close_time.minute)\n",
    "\n",
    "    # Define the coordinates for the current market\n",
    "    market_coords = (latitude, longitude)\n",
    "\n",
    "    # Initialize lists for new columns\n",
    "    num_list, sum_list, max_list, avg_list, min_dist_list, max_dist_list, sum_tsunami = [], [], [], [], [], [], []\n",
    "\n",
    "    # Process each row in df_ticker\n",
    "    for i, ticker_row in df_ticker.iterrows():\n",
    "        curr_date = ticker_row['date']\n",
    "        prev_date = df_ticker.iloc[i - 1]['date'] if i > 0 else None\n",
    "\n",
    "        # Define time window: after previous day's close and before current day's close\n",
    "        if prev_date is not None:\n",
    "            eq_filtered = df_eq[(df_eq['date'] > prev_date + pd.Timedelta(hours=close_time.hour, minutes=close_time.minute)) & \n",
    "                               (df_eq['date'] <= curr_date + pd.Timedelta(hours=close_time.hour, minutes=close_time.minute))]\n",
    "        else:\n",
    "            eq_filtered = df_eq[df_eq['date'] <= curr_date + pd.Timedelta(hours=close_time.hour, minutes=close_time.minute)]\n",
    "\n",
    "        # Compute required values\n",
    "        num_list.append(len(eq_filtered))\n",
    "        sum_list.append(eq_filtered['magnitudo'].sum() if not eq_filtered.empty else np.nan)\n",
    "        max_list.append(eq_filtered['magnitudo'].max() if not eq_filtered.empty else np.nan)\n",
    "        avg_list.append(eq_filtered['magnitudo'].mean() if not eq_filtered.empty else np.nan)\n",
    "        sum_tsunami.append(eq_filtered['tsunami'].sum() if not eq_filtered.empty else np.nan)\n",
    "        \n",
    "        # Compute distances from the market's location\n",
    "        if not eq_filtered.empty:\n",
    "            distances = eq_filtered.apply(lambda row: geodesic((row['latitude'], row['longitude']), market_coords).km, axis=1)\n",
    "            min_dist_list.append(distances.min())\n",
    "            max_dist_list.append(distances.max())\n",
    "        else:\n",
    "            min_dist_list.append(np.nan)\n",
    "            max_dist_list.append(np.nan)\n",
    "\n",
    "    # Create the combined df\n",
    "    df = df_ticker.copy()\n",
    "    df['num'] = num_list\n",
    "    df['sum'] = sum_list\n",
    "    df['max'] = max_list\n",
    "    df['avg'] = avg_list\n",
    "    df['min_dist'] = min_dist_list\n",
    "    df['max_dist'] = max_dist_list\n",
    "    df['tsunami'] = sum_tsunami\n",
    "\n",
    "    # Final preparations of the dataframe\n",
    "    df[['sum', 'max', 'avg', 'min_dist', 'max_dist', 'tsunami']] = df[['sum', 'max', 'avg', 'min_dist', 'max_dist', 'tsunami']].fillna(0)\n",
    "    df['rev_dist'] = df['min_dist'].apply(lambda x: 0 if x == 0 else 1 / x)\n",
    "\n",
    "    # Save the dataframe to a CSV file named according to the ticker\n",
    "    output_file = os.path.join(output_dir, f'{ticker}.csv')\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved data for ticker {ticker} to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
