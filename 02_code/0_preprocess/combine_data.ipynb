{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/EQ2008-23.csv')\n",
    "\n",
    "#removing all the earthquakes before August 1, 2008\n",
    "cutoff = pd.Timestamp('2008-07-31 00:00:00.00+00:00') #the last date before stock data begins\n",
    "df = df[df['date'] > cutoff] #removing rows before cutoff date\n",
    "\n",
    "df.to_csv('data/EQ2008-23.csv') #Earthquakes for the whole period we have stock data from, which we will use later\n",
    "\n",
    "#remove all EQs after 2009 for test\n",
    "df['date'] = pd.to_datetime(df['date'],format='ISO8601')\n",
    "cutoff = pd.Timestamp('2010-01-01 00:00:00.00+00:00') #the first date after 2009\n",
    "df = df[df['date'] < cutoff] #Removing rows before cutoff date\n",
    "df.to_csv('data/EQ2008-09.csv') #Earthquakes for 2008-09 period we wanna test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['magnitudo'] >= 6] #Removing all the earthquakes below 6 richter magnitude. We might wanna change this for the model\n",
    "df = df.drop(columns=['time', 'place', 'status', 'tsunami','data_type','state']) #Removing what seems to be unnecessary columns\n",
    "df.to_csv('data/test/EQtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining our stock data sets for the test\n",
    "df1 = pd.read_csv('data/2008_Global_Markets_Data.csv')\n",
    "df2 = pd.read_csv('data/2009_Global_Markets_Data.csv')\n",
    "df = pd.concat([df1,df2], axis=0)\n",
    "#Calculating the daily change, removing what seems to be unnecessary columns\n",
    "df['change'] = df['Close'] - df['Open']\n",
    "df = df.drop(columns=['Open','High', 'Low', 'Close','Adj Close', 'Volume'])\n",
    "df.to_csv('data/Stocktest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating the stock market data set into 12 separate data sets, for each ticker\n",
    "Tickers = df['Ticker'].unique()\n",
    "for ticker in Tickers:\n",
    "        df_alt = df[df['Ticker'] == ticker]\n",
    "        filename=\"data/test/\"+ticker+\".csv\"\n",
    "        df_alt.to_csv(filename, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
