{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file use to retrieve all companies' stock data for BSE Sensex (^BSESN) from 01/01/2007 to 31/12/2025\n",
    "## After that save all the data in a csv file name: \"BSESN_companies_stock.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import random\n",
    "from requests.exceptions import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure custom session with browser-like headers\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tickers and Data Parameters \n",
    "# Ticker list (BSESN 30 companies)\n",
    "TICKERS = [\n",
    "            \"M&M.BO\", \"MARUTI.BO\", \"TATAMOTORS.BO\", \"AXISBANK.BO\", \"HDFCBANK.BO\", \"ICICIBANK.BO\", \"INDUSINDBK.BO\", \"KOTAKBANK.BO\",\n",
    "    \"SBIN.BO\", \"ULTRACEMCO.BO\", \"ITC.BO\", \"RELIANCE.BO\", \"TITAN.BO\", \"ZOMATO.BO\", \"LT.BO\", \"BAJAJFINSV.BO\",\n",
    "    \"BAJFINANCE.BO\", \"HINDUNILVR.BO\", \"NESTLEIND.BO\", \"HCLTECH.BO\", \"INFY.BO\", \"TCS.BO\", \"TECHM.BO\", \"ASIANPAINT.BO\",\n",
    "    \"SUNPHARMA.BO\", \"ADANIPORTS.BO\", \"NTPC.BO\", \"POWERGRID.BO\", \"TATASTEEL.BO\", \"BHARTIARTL.BO\"\n",
    "]\n",
    "\n",
    "# Date parameters\n",
    "START_DATE = \"2007-01-01\"\n",
    "END_DATE = \"2025-12-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch stock data\n",
    "\n",
    "def fetch_stock_data(ticker, max_retries=3, initial_delay=5):\n",
    "    current_delay = initial_delay\n",
    "    for attempt in range(max_retries + 1):\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker, session=session)\n",
    "            data = stock.history(\n",
    "                start=START_DATE,\n",
    "                end=END_DATE,\n",
    "                interval=\"1d\",\n",
    "                actions=False\n",
    "            )\n",
    "            \n",
    "            if data.empty:\n",
    "                print(f\"No data for {ticker}\")\n",
    "                return None\n",
    "                \n",
    "            processed_data = data[['Open', 'Close', 'Volume']].reset_index()\n",
    "            processed_data['Date'] = pd.to_datetime(processed_data['Date']).dt.date\n",
    "            processed_data['Ticker'] = ticker  # Add Ticker column\n",
    "            return processed_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries:\n",
    "                sleep_time = current_delay + random.uniform(0, 3)\n",
    "                print(f\"Retry {attempt+1} for {ticker} in {sleep_time:.1f}s: {str(e)}\")\n",
    "                time.sleep(sleep_time)\n",
    "                current_delay *= 2\n",
    "            else:\n",
    "                print(f\"Failed {ticker} after {max_retries} retries\")\n",
    "                return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to fetch data for all companies\n",
    "\n",
    "def main():\n",
    "    all_data = []\n",
    "    total_tickers = len(TICKERS)\n",
    "    success_count = 0\n",
    "    \n",
    "    for idx, ticker in enumerate(TICKERS, 1):\n",
    "        print(f\"\\nProcessing {ticker} ({idx}/{total_tickers})\")\n",
    "        \n",
    "        # Random delay to avoid detection\n",
    "        time.sleep(random.uniform(0.5, 1.5))\n",
    "        \n",
    "        data = fetch_stock_data(ticker)\n",
    "        \n",
    "        if data is not None:\n",
    "            all_data.append(data)\n",
    "            success_count += 1\n",
    "            \n",
    "    if all_data:\n",
    "        # Merge all DataFrames\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # Save merged data\n",
    "        combined_df.to_csv(\"BSESN_companies_stock.csv\", index=False)\n",
    "        print(f\"\\nSuccessfully saved {len(combined_df)} rows from {success_count} companies\")\n",
    "        print(\"Columns in final dataset:\", combined_df.columns.tolist())\n",
    "    else:\n",
    "        print(\"\\nNo data was collected\")\n",
    "        \n",
    "    print(f\"\\nSuccess rate: {success_count}/{total_tickers} ({success_count/total_tickers:.1%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing M&M.BO (1/30)\n",
      "\n",
      "Processing MARUTI.BO (2/30)\n",
      "\n",
      "Processing TATAMOTORS.BO (3/30)\n",
      "\n",
      "Processing AXISBANK.BO (4/30)\n",
      "\n",
      "Processing HDFCBANK.BO (5/30)\n",
      "\n",
      "Processing ICICIBANK.BO (6/30)\n",
      "\n",
      "Processing INDUSINDBK.BO (7/30)\n",
      "\n",
      "Processing KOTAKBANK.BO (8/30)\n",
      "\n",
      "Processing SBIN.BO (9/30)\n",
      "\n",
      "Processing ULTRACEMCO.BO (10/30)\n",
      "\n",
      "Processing ITC.BO (11/30)\n",
      "\n",
      "Processing RELIANCE.BO (12/30)\n",
      "\n",
      "Processing TITAN.BO (13/30)\n",
      "\n",
      "Processing ZOMATO.BO (14/30)\n",
      "\n",
      "Processing LT.BO (15/30)\n",
      "\n",
      "Processing BAJAJFINSV.BO (16/30)\n",
      "\n",
      "Processing BAJFINANCE.BO (17/30)\n",
      "\n",
      "Processing HINDUNILVR.BO (18/30)\n",
      "\n",
      "Processing NESTLEIND.BO (19/30)\n",
      "\n",
      "Processing HCLTECH.BO (20/30)\n",
      "\n",
      "Processing INFY.BO (21/30)\n",
      "\n",
      "Processing TCS.BO (22/30)\n",
      "\n",
      "Processing TECHM.BO (23/30)\n",
      "\n",
      "Processing ASIANPAINT.BO (24/30)\n",
      "\n",
      "Processing SUNPHARMA.BO (25/30)\n",
      "\n",
      "Processing ADANIPORTS.BO (26/30)\n",
      "\n",
      "Processing NTPC.BO (27/30)\n",
      "\n",
      "Processing POWERGRID.BO (28/30)\n",
      "\n",
      "Processing TATASTEEL.BO (29/30)\n",
      "\n",
      "Processing BHARTIARTL.BO (30/30)\n",
      "\n",
      "Successfully saved 129414 rows from 30 companies\n",
      "Columns in final dataset: ['Date', 'Open', 'Close', 'Volume', 'Ticker']\n",
      "\n",
      "Success rate: 30/30 (100.0%)\n",
      "\n",
      "Total execution time: 0.70 minutes\n"
     ]
    }
   ],
   "source": [
    "# Execute the Script\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    main()\n",
    "    print(f\"\\nTotal execution time: {(time.time() - start_time)/60:.2f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
